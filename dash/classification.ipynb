{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../data/neo_task.csv\")\n",
    "data.drop(columns=[\"id\", \"name\"], inplace=True)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"hazardous\"])\n",
    "Y = data[\"hazardous\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "oversampled = SMOTE(random_state=0)\n",
    "X_smote, y_smote = oversampled.fit_resample(np.array(X_scaled), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>est_diameter_min</th>\n",
       "      <th>est_diameter_max</th>\n",
       "      <th>relative_velocity</th>\n",
       "      <th>miss_distance</th>\n",
       "      <th>absolute_magnitude</th>\n",
       "      <th>hazardous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.235700</td>\n",
       "      <td>0.013606</td>\n",
       "      <td>0.703796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.032354</td>\n",
       "      <td>0.436880</td>\n",
       "      <td>0.645390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.232505</td>\n",
       "      <td>0.874154</td>\n",
       "      <td>0.591156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.174537</td>\n",
       "      <td>0.168484</td>\n",
       "      <td>0.687109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.284797</td>\n",
       "      <td>0.953300</td>\n",
       "      <td>0.507718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160947</th>\n",
       "      <td>0.007207</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>0.184602</td>\n",
       "      <td>0.323308</td>\n",
       "      <td>0.446664</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160948</th>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.228412</td>\n",
       "      <td>0.364040</td>\n",
       "      <td>0.526252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160949</th>\n",
       "      <td>0.007155</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>0.144024</td>\n",
       "      <td>0.895314</td>\n",
       "      <td>0.447463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160950</th>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.311526</td>\n",
       "      <td>0.168684</td>\n",
       "      <td>0.529701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160951</th>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.185287</td>\n",
       "      <td>0.397718</td>\n",
       "      <td>0.529259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160952 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        est_diameter_min  est_diameter_max  relative_velocity  miss_distance  \\\n",
       "0               0.000407          0.000407           0.235700       0.013606   \n",
       "1               0.000789          0.000789           0.032354       0.436880   \n",
       "2               0.001450          0.001450           0.232505       0.874154   \n",
       "3               0.000492          0.000492           0.174537       0.168484   \n",
       "4               0.003665          0.003665           0.284797       0.953300   \n",
       "...                  ...               ...                ...            ...   \n",
       "160947          0.007207          0.007207           0.184602       0.323308   \n",
       "160948          0.002985          0.002985           0.228412       0.364040   \n",
       "160949          0.007155          0.007155           0.144024       0.895314   \n",
       "160950          0.002873          0.002873           0.311526       0.168684   \n",
       "160951          0.002887          0.002887           0.185287       0.397718   \n",
       "\n",
       "        absolute_magnitude  hazardous  \n",
       "0                 0.703796          0  \n",
       "1                 0.645390          0  \n",
       "2                 0.591156          0  \n",
       "3                 0.687109          0  \n",
       "4                 0.507718          0  \n",
       "...                    ...        ...  \n",
       "160947            0.446664          1  \n",
       "160948            0.526252          1  \n",
       "160949            0.447463          1  \n",
       "160950            0.529701          1  \n",
       "160951            0.529259          1  \n",
       "\n",
       "[160952 rows x 6 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([pd.DataFrame(X_smote, columns=X.columns), pd.DataFrame(y_smote, columns=pd.DataFrame(Y).columns)], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"classification_pred.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/classification_pred.csv\")\n",
    "data = data.dropna()\n",
    "data\n",
    "X = data.drop(columns=[\"hazardous\"])\n",
    "Y = data[\"hazardous\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.3, stratify=Y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91     20940\n",
      "           1       0.99      0.87      0.93     27346\n",
      "\n",
      "    accuracy                           0.92     48286\n",
      "   macro avg       0.92      0.93      0.92     48286\n",
      "weighted avg       0.93      0.92      0.92     48286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3, p=2).fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_pred, y_test))\n",
    "knn_pipeline = Pipeline([('scaler', scaler), ('knn', knn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn.joblib']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(knn_pipeline, \"knn.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91     24143\n",
      "           1       0.87      0.99      0.92     24143\n",
      "\n",
      "    accuracy                           0.92     48286\n",
      "   macro avg       0.93      0.92      0.92     48286\n",
      "weighted avg       0.93      0.92      0.92     48286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging = BaggingClassifier(knn, n_estimators=11).fit(X_train, y_train)\n",
    "y_pred = bagging.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "pipeline_bagging = Pipeline([('scaler', scaler), ('bagging', bagging)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bagging.joblib']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(knn_pipeline, \"bagging.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eaa912a9b0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_classification = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model_classification.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"binary_crossentropy\")\n",
    "model_classification.fit(X_train, y_train, epochs=25, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     24143\n",
      "           1       0.00      0.00      0.00     24143\n",
      "\n",
      "    accuracy                           0.50     48286\n",
      "   macro avg       0.25      0.50      0.33     48286\n",
      "weighted avg       0.25      0.50      0.33     48286\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ÐŸÐ¾Ð»Ð¸Ð½Ð°\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ÐŸÐ¾Ð»Ð¸Ð½Ð°\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ÐŸÐ¾Ð»Ð¸Ð½Ð°\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = [np.argmax(pred) for pred in model_classification.predict(X_test, verbose=None)]\n",
    "print(classification_report(y_test, y_pred))\n",
    "pipeline_tf = Pipeline([('scaler', scaler), ('dence', model_classification)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tf.joblib']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline_tf, \"tf.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
